"""
Run ESMFold multimer + pDockQ scoring on toxin-antitoxin protein pairs.

Usage:
    python pipelines/toxin_antitoxin_cofold.py --config path/to/config.yaml

This script is intentionally environment-agnostic so you can run it inside the
ESMFold / PyTorch environment. The config simply points to the CSV generated by
`toxin_antitoxin_sample.py` (paired proteins) and to the local ESM_Fold repo.
"""

import argparse
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List

PACKAGE_ROOT = Path(__file__).resolve().parents[1]
if str(PACKAGE_ROOT) not in sys.path:
    sys.path.insert(0, str(PACKAGE_ROOT))

import pandas as pd
import yaml


def sanitize_identifier(value: str) -> str:
    """Return a filesystem-friendly identifier derived from arbitrary text."""
    safe = "".join(ch for ch in value if ch.isalnum() or ch in ("-", "_"))
    return safe or "pair"


@dataclass
class CofoldConfig:
    """Configuration for toxinâ€“antitoxin co-folding + pDockQ scoring."""

    pairs_csv: Path  # CSV produced by identify_unique_pairs
    output_dir: Path  # Directory for co-fold inputs, PDBs, and score summaries
    esm_fold_repo: Path  # Path to /large_storage/.../ESM_Fold

    # Column names used in the pairs CSV
    root_id_col: str = "Root_ID"
    sequence1_col: str = "Amino Acid Sequence 1"
    sequence2_col: str = "Amino Acid Sequence 2"
    sequence1_id_col: str = "Evo Sequence ID 1"
    sequence2_id_col: str = "Evo Sequence ID 2"

    run_esmfold: bool = True
    run_pdockq: bool = True
    pdockq_threshold: float = 0.23

    cofold_input_csv: Path = field(init=False)
    esmfold_output_dir: Path = field(init=False)
    pdockq_scores_csv: Path = field(init=False)
    pdockq_summary_csv: Path = field(init=False)
    pdockq_filtered_csv: Path = field(init=False)
    pdockq_filtered_fasta: Path = field(init=False)

    def __post_init__(self) -> None:
        self.pairs_csv = Path(self.pairs_csv)
        self.output_dir = Path(self.output_dir)
        self.esm_fold_repo = Path(self.esm_fold_repo)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.cofold_input_csv = self.output_dir / "cofold_input.csv"
        self.esmfold_output_dir = self.output_dir / "esmfold_structures"
        self.esmfold_output_dir.mkdir(parents=True, exist_ok=True)
        self.pdockq_scores_csv = self.output_dir / "pdockq_scores.csv"
        self.pdockq_summary_csv = self.output_dir / "pdockq_summary.csv"
        self.pdockq_filtered_csv = self.output_dir / "pdockq_high_confidence.csv"
        self.pdockq_filtered_fasta = self.output_dir / "pdockq_high_confidence.fasta"


def load_config(config_path: Path) -> CofoldConfig:
    """Load YAML configuration file."""
    with open(config_path, "r") as handle:
        data = yaml.safe_load(handle)
    if not isinstance(data, dict):
        raise ValueError(f"Configuration must be a mapping: {config_path}")
    return CofoldConfig(**data)


def prepare_cofold_inputs(config: CofoldConfig) -> pd.DataFrame:
    """Convert toxin-antitoxin pair CSV into esmfold_multimer input format."""
    df = pd.read_csv(config.pairs_csv)
    required_columns = [
        config.root_id_col,
        config.sequence1_col,
        config.sequence2_col,
        config.sequence1_id_col,
        config.sequence2_id_col,
    ]
    missing = [col for col in required_columns if col not in df.columns]
    if missing:
        raise ValueError(f"Missing required columns in {config.pairs_csv}: {missing}")

    def build_id(row: pd.Series) -> str:
        root = str(row[config.root_id_col])
        seq1_id = str(row[config.sequence1_id_col])
        seq2_id = str(row[config.sequence2_id_col])
        return sanitize_identifier(f"{root}_{seq1_id}_{seq2_id}")

    cofold_df = pd.DataFrame(
        {
            "sequence1": df[config.sequence1_col].astype(str),
            "sequence2": df[config.sequence2_col].astype(str),
            "id_pair": [build_id(row) for _, row in df.iterrows()],
        }
    )
    cofold_df = cofold_df.drop_duplicates(subset="id_pair").reset_index(drop=True)
    cofold_df.to_csv(config.cofold_input_csv, index=False)
    return cofold_df


def ensure_esm_repo_on_path(config: CofoldConfig) -> None:
    repo_path = str(config.esm_fold_repo)
    if repo_path not in sys.path:
        sys.path.insert(0, repo_path)


def run_esmfold(config: CofoldConfig, cofold_df: pd.DataFrame) -> None:
    """Fold toxin/antitoxin pairs using esmfold_multimer."""
    ensure_esm_repo_on_path(config)
    from esmfold_multimer import fold_sequences  # type: ignore

    fold_sequences(
        list(cofold_df["sequence1"]),
        list(cofold_df["sequence2"]),
        list(cofold_df["id_pair"]),
        str(config.esmfold_output_dir),
    )


def extract_pdockq_scores(config: CofoldConfig) -> None:
    """Walk the ESMFold output directory and extract pDockQ metrics."""
    ensure_esm_repo_on_path(config)
    from pdockq import extract_pdockq_data  # type: ignore

    extract_pdockq_data(str(config.esmfold_output_dir), str(config.pdockq_scores_csv))


def summarize_pdockq(
    config: CofoldConfig, cofold_df: pd.DataFrame, pdockq_df: pd.DataFrame
) -> None:
    """Merge pdockQ scores with sequence metadata and emit reports."""
    if pdockq_df.empty:
        print("No pDockQ scores were extracted. Skipping summary generation.")
        return

    pdockq_df["id_pair"] = pdockq_df["PDB_File"].apply(lambda p: Path(p).stem)
    for col in ["pDockQ", "if_pLDDT", "if_contacts", "avg_pLDDT"]:
        pdockq_df[col] = pd.to_numeric(pdockq_df[col], errors="coerce")

    merged = pdockq_df.merge(cofold_df, on="id_pair", how="left")
    merged = merged.sort_values(by="pDockQ", ascending=False)
    merged.to_csv(config.pdockq_summary_csv, index=False)

    high_conf = merged[merged["pDockQ"] >= config.pdockq_threshold]
    high_conf.to_csv(config.pdockq_filtered_csv, index=False)

    if high_conf.empty:
        print(
            f"No complexes exceeded pDockQ >= {config.pdockq_threshold}. "
            "Skipping FASTA export."
        )
        return

    with open(config.pdockq_filtered_fasta, "w") as fasta_handle:
        for _, row in high_conf.iterrows():
            fasta_handle.write(f">{row['id_pair']}_tox\n{row['sequence1']}\n")
            fasta_handle.write(f">{row['id_pair']}_antitox\n{row['sequence2']}\n")


def run_pipeline(config: CofoldConfig) -> None:
    cofold_df = prepare_cofold_inputs(config)

    if config.run_esmfold:
        print("Running ESMFold multimer on toxin-antitoxin pairs...", flush=True)
        run_esmfold(config, cofold_df)
    else:
        print("Skipping ESMFold run (run_esmfold=False).", flush=True)

    if config.run_pdockq:
        print("Extracting pDockQ metrics...", flush=True)
        extract_pdockq_scores(config)
        pdockq_df = pd.read_csv(config.pdockq_scores_csv)
        summarize_pdockq(config, cofold_df, pdockq_df)
    else:
        print("Skipping pDockQ extraction (run_pdockq=False).", flush=True)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run ESMFold multimer + pDockQ scoring on toxin-antitoxin pairs."
    )
    parser.add_argument(
        "--config",
        required=True,
        help="Path to YAML config describing pair CSV and ESMFold repo location.",
    )
    args = parser.parse_args()
    run_pipeline(load_config(Path(args.config)))
