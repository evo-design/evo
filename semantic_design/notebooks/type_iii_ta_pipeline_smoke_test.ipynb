{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Type III TA Pipeline Smoke Tests\n",
        "This notebook creates tiny synthetic datasets to exercise the filtering utilities in `type_iii_ta_sample.py` and to run a fully patched pipeline smoke test. The heavy external tools (Evo sampling, TRF, HMMER, Infernal) are replaced with lightweight stubs so we can validate code paths quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bfa5fa2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temporary workspace: /tmp/type_iii_ta_tests_hf0inesj\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from importlib import reload\n",
        "from types import SimpleNamespace\n",
        "\n",
        "BASE_TMP = Path(tempfile.mkdtemp(prefix=\"type_iii_ta_tests_\"))\n",
        "print(f\"Temporary workspace: {BASE_TMP}\")\n",
        "\n",
        "from semantic_design.pipelines import type_iii_ta_sample as pipeline\n",
        "pipeline = reload(pipeline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207fa1ee",
      "metadata": {},
      "source": [
        "## Helper utilities\n",
        "Supporting functions to fabricate stub CLI tools and reference tables used throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b7501c6e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stub scripts written to /tmp/type_iii_ta_tests_hf0inesj/stub_structure_filter.py and /tmp/type_iii_ta_tests_hf0inesj/stub_sequence_filter.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import textwrap\n",
        "\n",
        "structure_stub_path = BASE_TMP / \"stub_structure_filter.py\"\n",
        "structure_stub_path.write_text(textwrap.dedent(\"\"\"\n",
        "    import argparse\n",
        "    import pandas as pd\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--query', required=True)\n",
        "    parser.add_argument('--target', required=True)\n",
        "    parser.add_argument('--output', required=True)\n",
        "    parser.add_argument('--structure-type')\n",
        "    parser.add_argument('--min-similarity')\n",
        "    parser.add_argument('--pre-filter-threshold')\n",
        "    parser.add_argument('--batch-size')\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    candidates = pd.read_csv(args.query)\n",
        "    keep = candidates[candidates['Root ID'].str.contains('A')]\n",
        "    if keep.empty:\n",
        "        keep = candidates.head(1)\n",
        "    pd.DataFrame({'Query_ID': keep['Root ID']}).to_csv(args.output, index=False)\n",
        "\"\"\"))\n",
        "\n",
        "sequence_stub_path = BASE_TMP / \"stub_sequence_filter.py\"\n",
        "sequence_stub_path.write_text(textwrap.dedent(\"\"\"\n",
        "    import argparse\n",
        "    import pandas as pd\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--reference_csv', required=True)\n",
        "    parser.add_argument('--comparison_csv', required=True)\n",
        "    parser.add_argument('--output_csv', required=True)\n",
        "    parser.add_argument('--min-identity')\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    candidates = pd.read_csv(args.comparison_csv).copy()\n",
        "    scores = candidates[['Root ID']].rename(columns={'Root ID': 'comp_root_id'})\n",
        "    scores['identity_percent'] = 95.0\n",
        "    scores.to_csv(args.output_csv, index=False)\n",
        "\"\"\"))\n",
        "\n",
        "print(f\"Stub scripts written to {structure_stub_path} and {sequence_stub_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8e8bb3",
      "metadata": {},
      "source": [
        "## 1. Build synthetic TRF / RNA tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "977d3113",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Passing TRF roots: {'rootA'}\n",
            "  Root ID Sequence_ID\n",
            "0   rootA  rootA_1_60\n",
            ">rootA_1_60 rootA\n",
            "AUGCGUACGAUCGUACGAUCGUAAACCGGUU\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trf_columns = [\n",
        "    'Root ID','Start','End','Period Size','Copy Number','Consensus Size','Percent Match',\n",
        "    'Percent Indels','Alignment Score','A','C','G','T','Entropy','Repeat Sequence','Full TRF Region'\n",
        "]\n",
        "trf_sample = pd.DataFrame([\n",
        "    ['rootA', 1, 60, 10, 3, 30, 95.0, 2.0, 200, 15, 15, 15, 15, 1.2, 'ATGCATGCAT', 'ATGCGTACGATCGTACGATCGTAAACCGGTT'],\n",
        "    ['rootB', 5, 80, 12, 4, 36, 90.0, 4.0, 180, 20, 10, 20, 10, 1.5, 'TTAACCGG', 'TTAACCGGTTAACCGGTTAACCGGTTAA'],\n",
        "    ['rootC', 10, 55, 8, 5, 24, 88.0, 5.0, 150, 12, 12, 12, 12, 1.7, 'GGCC', 'GGCCATATGGCCATATGGCCATATGGCC']\n",
        "], columns=trf_columns)\n",
        "\n",
        "fold_sample = pd.DataFrame([\n",
        "    {\n",
        "        'Evo Sequence ID': 'rootA',\n",
        "        'Description': 'rootA test',\n",
        "        'DNA Sequence': trf_sample.loc[0, 'Full TRF Region'],\n",
        "        'RNA Sequence': 'AUGCGUACGAUCGUACGAUCGUAAACCGGUU',\n",
        "        'Secondary Structure': '((((....))))....((((....))))',\n",
        "        'MFE': -12.0,\n",
        "        'Hairpins': [(2, 12, 3, 11)]\n",
        "    },\n",
        "    {\n",
        "        'Evo Sequence ID': 'rootB',\n",
        "        'Description': 'rootB test',\n",
        "        'DNA Sequence': trf_sample.loc[1, 'Full TRF Region'],\n",
        "        'RNA Sequence': 'UUAAUUGGCUUAAUUGGCUUAAUUGGCUU',\n",
        "        'Secondary Structure': '...(((....)))...',\n",
        "        'MFE': -4.5,\n",
        "        'Hairpins': []\n",
        "    }\n",
        "])\n",
        "\n",
        "filter_cfg = SimpleNamespace(\n",
        "    rna_require_hairpin=True,\n",
        "    rna_minimum_mfe=-3.0,\n",
        "    rna_require_all_bases=True,\n",
        "    rna_fold_csv=BASE_TMP / 'filtered_rna_fold.csv'\n",
        ")\n",
        "\n",
        "filtered_fold, passing_ids = pipeline.filter_folded_trfs(trf_sample, fold_sample, filter_cfg)\n",
        "print('Passing TRF roots:', passing_ids)\n",
        "\n",
        "candidate_csv_path = BASE_TMP / 'rna_candidates.csv'\n",
        "candidate_table = pipeline.prepare_rna_candidate_table(trf_sample, filtered_fold, candidate_csv_path)\n",
        "print(candidate_table[['Root ID','Sequence_ID']])\n",
        "\n",
        "candidate_fasta_path = BASE_TMP / 'rna_candidates.fasta'\n",
        "pipeline.write_rna_candidates_fasta(candidate_table, candidate_fasta_path)\n",
        "print(candidate_fasta_path.read_text())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "516303ea",
      "metadata": {},
      "source": [
        "## 2. Test RNA structure/sequence filters via stubs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c2bf999d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Structure hits: {'rootA'}\n",
            "Sequence hits: {'rootA'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "reference_rna_path = BASE_TMP / 'reference_rnas.csv'\n",
        "reference_df = candidate_table.copy()\n",
        "reference_df.to_csv(reference_rna_path, index=False)\n",
        "\n",
        "structure_cfg = SimpleNamespace(\n",
        "    rna_structure_filter_script=Path(str(structure_stub_path)),\n",
        "    rna_structure_filter_reference_csv=reference_rna_path,\n",
        "    rna_structures_reference_csv=reference_rna_path,\n",
        "    rna_structure_matches_csv=BASE_TMP / 'structure_hits.csv',\n",
        "    rna_structure_filter_structure_type='both',\n",
        "    rna_structure_filter_min_similarity=0.7,\n",
        "    rna_structure_filter_pre_filter_threshold=0.7,\n",
        "    rna_structure_filter_batch_size=10,\n",
        "    rna_structure_filter_max_results=None,\n",
        "    rna_structure_filter_cpus=None\n",
        ")\n",
        "structure_hits = pipeline.run_rna_structure_filter(candidate_csv_path, structure_cfg)\n",
        "print('Structure hits:', structure_hits)\n",
        "\n",
        "sequence_cfg = SimpleNamespace(\n",
        "    rna_sequence_filter_script=Path(str(sequence_stub_path)),\n",
        "    rna_sequence_filter_reference_csv=reference_rna_path,\n",
        "    rna_structures_reference_csv=reference_rna_path,\n",
        "    rna_sequence_matches_csv=BASE_TMP / 'sequence_hits.csv',\n",
        "    rna_sequence_filter_min_identity=70.0,\n",
        "    rna_sequence_filter_processes=None\n",
        ")\n",
        "sequence_hits = pipeline.run_rna_sequence_filter(candidate_csv_path, sequence_cfg)\n",
        "print('Sequence hits:', sequence_hits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff91105",
      "metadata": {},
      "source": [
        "## 3. Test Pfam hmmscan filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0ba62b41",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  sequence_id   pfam_name       e_value\n",
            "0     rootA_0  ToxN_toxin  1.000000e-25\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from unittest.mock import patch\n",
        "from subprocess import CompletedProcess\n",
        "\n",
        "domtbl_line = \" \".join([\n",
        "    'ToxN_toxin','PF13958.10','159','rootA_0','-','150','1e-20','50.0','0.0',\n",
        "    '1','1','1e-25','1e-25','45.2','0.1','5','120','3','128','3','128','0.95','ToxN_toxin'\n",
        "])\n",
        "\n",
        "aaid_fasta = BASE_TMP / 'dummy_proteins.faa'\n",
        "aaid_fasta.write_text('>rootA_0\\nMSTNKKLLDN')\n",
        "pfam_db_path = BASE_TMP / 'Pfam-A.hmm'\n",
        "pfam_db_path.write_text('# dummy Pfam DB')\n",
        "pfam_reference_path = BASE_TMP / 'pfam_reference.csv'\n",
        "pd.DataFrame({'pfam_name': ['ToxN_toxin']}).to_csv(pfam_reference_path, index=False)\n",
        "\n",
        "hmmscan_cfg = SimpleNamespace(\n",
        "    hmmscan_pfam_db_path=pfam_db_path,\n",
        "    filtered_proteins_file=aaid_fasta,\n",
        "    hmmscan_binary='hmmscan',\n",
        "    hmmscan_cpu=1,\n",
        "    hmmscan_domtblout=BASE_TMP / 'hmmscan.domtblout',\n",
        "    hmmscan_hits_csv=BASE_TMP / 'hmmscan_hits.csv',\n",
        "    pfam_reference_hits_csv=pfam_reference_path,\n",
        "    pfam_evalue_threshold=0.05\n",
        ")\n",
        "\n",
        "def fake_hmmscan(cmd, check, **kwargs):\n",
        "    hmmscan_cfg.hmmscan_domtblout.write_text(f\"# dummy\\n{domtbl_line}\")\n",
        "    return CompletedProcess(cmd, 0)\n",
        "\n",
        "with patch('semantic_design.pipelines.type_iii_ta_sample.subprocess.run', side_effect=fake_hmmscan):\n",
        "    hmmscan_hits = pipeline.run_hmmscan_filter(hmmscan_cfg)\n",
        "\n",
        "print(hmmscan_hits[['sequence_id','pfam_name','e_value']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f6bac99",
      "metadata": {},
      "source": [
        "## 4. Test cmscan filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c7648e2f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>target_name</th>\n",
              "      <th>Root ID</th>\n",
              "      <th>e_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rootA_1_60</td>\n",
              "      <td>ToxI</td>\n",
              "      <td>rootA</td>\n",
              "      <td>0.000001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sequence_id target_name Root ID   e_value\n",
              "0  rootA_1_60        ToxI   rootA  0.000001"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Regenerate candidate table snapshot to ensure this cell works independently\n",
        "if 'candidate_csv_path' not in globals() or not candidate_csv_path.exists():\n",
        "    raise RuntimeError('Run the TRF/RNA preparation cell before executing the cmscan test.')\n",
        "\n",
        "candidate_table_snapshot = pd.read_csv(candidate_csv_path)\n",
        "if candidate_table_snapshot.empty:\n",
        "    raise RuntimeError('Candidate table is empty; construct synthetic TRF/RNA data before running cmscan.')\n",
        "\n",
        "candidate_table_snapshot['Sequence_ID'] = candidate_table_snapshot['Sequence_ID'].astype(str)\n",
        "candidate_table_snapshot['Root ID'] = candidate_table_snapshot['Root ID'].astype(str)\n",
        "\n",
        "cmscan_fasta_path = BASE_TMP / 'cmscan_rna_candidates.fasta'\n",
        "pipeline.write_rna_candidates_fasta(candidate_table_snapshot, cmscan_fasta_path)\n",
        "\n",
        "cm_file = BASE_TMP / 'toy.cm'\n",
        "cm_file.write_text('# mock CM file')\n",
        "seq_ids = candidate_table_snapshot['Sequence_ID'].tolist()\n",
        "\n",
        "cmscan_cfg = SimpleNamespace(\n",
        "    cmscan_model_paths=[cm_file],\n",
        "    cmscan_tblout_dir=BASE_TMP / 'cmscan_tblout',\n",
        "    cmscan_hits_csv=BASE_TMP / 'cmscan_hits.csv',\n",
        "    cmscan_binary='cmscan',\n",
        "    cmscan_evalue_threshold=0.05,\n",
        "    cmscan_allowed_families=['ToxI'],\n",
        "    cmscan_allowed_families_csv=None,\n",
        "    cmscan_allowed_families_column='Query Name',\n",
        "    rna_candidates_fasta=cmscan_fasta_path\n",
        ")\n",
        "cmscan_cfg.cmscan_tblout_dir.mkdir(exist_ok=True)\n",
        "\n",
        "from subprocess import CompletedProcess\n",
        "\n",
        "def fake_cmscan(cmd, check, **kwargs):\n",
        "    tblout_path = Path(cmd[2])\n",
        "    entries = [\n",
        "        f\"ToxI RF02519 {seq_ids[0]} - cm 1 34 10 40 + no 1 0.5 0.0 40.0 1e-6 ! ToxI antitoxin\"\n",
        "    ]\n",
        "    tblout_path.write_text(''.join(entries) + '')\n",
        "    return CompletedProcess(cmd, 0)\n",
        "\n",
        "with patch('semantic_design.pipelines.type_iii_ta_sample.subprocess.run', side_effect=fake_cmscan):\n",
        "    cmscan_hits = pipeline.run_cmscan_filter(candidate_table_snapshot, cmscan_cfg)\n",
        "\n",
        "if cmscan_hits.empty:\n",
        "    raise RuntimeError('Synthetic cmscan stub returned no hits; ensure the candidate table has at least one entry.')\n",
        "else:\n",
        "    display(cmscan_hits[['sequence_id','target_name','Root ID','e_value']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4935397",
      "metadata": {},
      "source": [
        "## 5. Pipeline smoke test with patched heavy steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cbd190af",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline completed successfully.\n",
            "Final candidates:\n",
            "  Evo Sequence ID Root ID\n",
            "0         rootA_0   rootA\n",
            "1         rootB_0   rootB\n",
            "2         rootC_0   rootC\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import yaml\n",
        "from contextlib import ExitStack\n",
        "from unittest.mock import patch\n",
        "\n",
        "pipeline_output_dir = BASE_TMP / 'pipeline_run'\n",
        "pipeline_config_path = BASE_TMP / 'pipeline_smoke.yaml'\n",
        "pipeline_prompts = BASE_TMP / 'prompts.csv'\n",
        "pipeline_prompts.write_text('prompt\\nDummy context')\n",
        "\n",
        "config_payload = {\n",
        "    'input_prompts': str(pipeline_prompts),\n",
        "    'output_dir': str(pipeline_output_dir),\n",
        "    'segmasker_path': '/bin/echo',\n",
        "    'trf_path': '/bin/echo',\n",
        "    'rna_structures_reference_csv': str(reference_rna_path),\n",
        "    'model_name': 'dummy',\n",
        "    'n_tokens': 32,\n",
        "    'temperature': 0.7,\n",
        "    'top_k': 4,\n",
        "    'batched': False,\n",
        "    'batch_size': 1,\n",
        "    'n_sample_per_prompt': 1,\n",
        "    'rc_truth': False,\n",
        "    'return_both': False,\n",
        "    'filter_min_length': 50,\n",
        "    'filter_max_length': 400,\n",
        "    'filter_partial_bool': False,\n",
        "    'segmasker_threshold': 0.2,\n",
        "    'run_esm_fold': True,\n",
        "    'plddt_threshold': 0.3,\n",
        "    'ptm_threshold': 0.0,\n",
        "    'write_trf_to_csv': True,\n",
        "    'rna_structure_filter_script': str(structure_stub_path),\n",
        "    'rna_sequence_filter_script': str(sequence_stub_path),\n",
        "    'rna_structure_filter_reference_csv': str(reference_rna_path),\n",
        "    'rna_sequence_filter_reference_csv': str(reference_rna_path),\n",
        "    'hmmscan_pfam_db_path': None,\n",
        "    'cmscan_model_paths': []\n",
        "}\n",
        "\n",
        "with open(pipeline_config_path, 'w') as handle:\n",
        "    yaml.safe_dump(config_payload, handle)\n",
        "\n",
        "root_ids = ['rootA','rootB','rootC']\n",
        "dna_sequences = ['ATGCGTACGATCGTACGATCGTAAACCGGTT', 'TTGACCGGTTGACCGGTTGACCGGTTGACC', 'GGCATATGGCATATGGCATATGGCAAA']\n",
        "protein_sequences = ['MKTAYIAKQRQISFVKSHFSRQ', 'MKKLLPTAAAGLLLLAAQPAMA', 'MADQLTEEQIAEFKEAF']\n",
        "\n",
        "trf_stub = pd.DataFrame([\n",
        "    {\n",
        "        'Root ID': rid,\n",
        "        'Start': 1,\n",
        "        'End': 60,\n",
        "        'Period Size': 10,\n",
        "        'Copy Number': 3,\n",
        "        'Consensus Size': 30,\n",
        "        'Percent Match': 95.0,\n",
        "        'Percent Indels': 1.0,\n",
        "        'Alignment Score': 200,\n",
        "        'A': 15,\n",
        "        'C': 15,\n",
        "        'G': 15,\n",
        "        'T': 15,\n",
        "        'Entropy': 1.1,\n",
        "        'Repeat Sequence': 'ATGC',\n",
        "        'Full TRF Region': dna_sequences[idx]\n",
        "    }\n",
        "    for idx, rid in enumerate(root_ids)\n",
        "])\n",
        "\n",
        "fold_stub = pd.DataFrame([\n",
        "    {\n",
        "        'Evo Sequence ID': rid,\n",
        "        'Description': rid,\n",
        "        'DNA Sequence': dna_sequences[idx],\n",
        "        'RNA Sequence': dna_sequences[idx].replace('T','U'),\n",
        "        'Secondary Structure': '(((())))....(((())))',\n",
        "        'MFE': -10.0,\n",
        "        'Hairpins': [(1, 8, 2, 7)]\n",
        "    }\n",
        "    for idx, rid in enumerate(root_ids)\n",
        "])\n",
        "\n",
        "filtered_fold_stub = pd.DataFrame([\n",
        "    {\n",
        "        'Evo Sequence ID': f'{rid}_0',\n",
        "        'Average pLDDT': 0.85,\n",
        "        'pTM': 0.6,\n",
        "        'Amino Acid Sequence': protein_sequences[idx]\n",
        "    }\n",
        "    for idx, rid in enumerate(root_ids)\n",
        "])\n",
        "\n",
        "def fake_read_prompts(path, batched, batch_size):\n",
        "    return [['Dummy context']]\n",
        "\n",
        "def fake_model_load(name):\n",
        "    return None, None\n",
        "\n",
        "def fake_sample_model(**kwargs):\n",
        "    ids = [f'{rid}_0' for rid in root_ids]\n",
        "    df = pd.DataFrame({'UUID': root_ids, 'Generated Sequence': dna_sequences})\n",
        "    df.to_csv(kwargs['file_save_location'], index=False)\n",
        "    return ['prompt'] * len(root_ids), dna_sequences, [0.0] * len(root_ids), ids\n",
        "\n",
        "def fake_get_rc(seqs, rc_truth=False, return_both=False):\n",
        "    return seqs\n",
        "\n",
        "def fake_make_fasta(final_sequences, prompts, ids, path):\n",
        "    with open(path, 'w') as handle:\n",
        "        for seq_id, seq in zip(ids, final_sequences):\n",
        "            handle.write(f'>{seq_id}\\n{seq}')\n",
        "\n",
        "def fake_run_prodigal(fasta_path, proteins_path, orfs_path):\n",
        "    Path(proteins_path).write_text(''.join([f'>{rid}_0\\n{protein_sequences[idx]}' for idx, rid in enumerate(root_ids)]))\n",
        "    Path(orfs_path).write_text('>dummy_orf\\nATGCGT')\n",
        "\n",
        "def fake_filter_protein_fasta(input_fasta, output_fasta, *args, **kwargs):\n",
        "    Path(output_fasta).write_text(Path(input_fasta).read_text())\n",
        "    return len(root_ids)\n",
        "\n",
        "def fake_fold_proteins(filtered_path, output_csv):\n",
        "    filtered_fold_stub.to_csv(output_csv, index=False)\n",
        "    return filtered_fold_stub.copy()\n",
        "\n",
        "def fake_get_tandem_repeats(filtered_folds, sequences_csv, config):\n",
        "    return trf_stub.copy()\n",
        "\n",
        "def fake_fold_trfs(trf_df, output_csv):\n",
        "    fold_stub.to_csv(output_csv, index=False)\n",
        "    return fold_stub.copy()\n",
        "\n",
        "def fake_visualize(*args, **kwargs):\n",
        "    return [], []\n",
        "\n",
        "def fake_get_at_pairs(*args, **kwargs):\n",
        "    return pd.DataFrame()\n",
        "\n",
        "with ExitStack() as stack:\n",
        "    stack.enter_context(patch.object(pipeline, 'read_prompts', side_effect=fake_read_prompts))\n",
        "    stack.enter_context(patch.object(pipeline, 'model_load', side_effect=fake_model_load))\n",
        "    stack.enter_context(patch.object(pipeline, 'sample_model', side_effect=fake_sample_model))\n",
        "    stack.enter_context(patch.object(pipeline, 'get_rc', side_effect=fake_get_rc))\n",
        "    stack.enter_context(patch.object(pipeline, 'make_fasta', side_effect=fake_make_fasta))\n",
        "    stack.enter_context(patch.object(pipeline, 'run_prodigal', side_effect=fake_run_prodigal))\n",
        "    stack.enter_context(patch.object(pipeline, 'filter_protein_fasta', side_effect=fake_filter_protein_fasta))\n",
        "    stack.enter_context(patch.object(pipeline, 'fold_proteins', side_effect=fake_fold_proteins))\n",
        "    stack.enter_context(patch.object(pipeline, 'get_tandem_repeats', side_effect=fake_get_tandem_repeats))\n",
        "    stack.enter_context(patch.object(pipeline, 'fold_trfs', side_effect=fake_fold_trfs))\n",
        "    stack.enter_context(patch.object(pipeline, 'visualize_rna_structures', side_effect=fake_visualize))\n",
        "    stack.enter_context(patch.object(pipeline, 'get_at_pairs', side_effect=fake_get_at_pairs))\n",
        "    pipeline.run_pipeline(pipeline_config_path)\n",
        "\n",
        "final_candidates = pd.read_csv(pipeline_output_dir / 'filtered_type_iii_candidates.csv')\n",
        "print('Final candidates:')\n",
        "print(final_candidates[['Evo Sequence ID','Root ID']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The notebook now exercises each filtering routine and runs a mocked end-to-end pipeline. Point the stubs to real binaries/CM files whenever you want to validate against production assets."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sm-evo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
